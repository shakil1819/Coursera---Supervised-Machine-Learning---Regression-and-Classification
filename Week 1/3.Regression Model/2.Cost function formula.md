<iframe src="https://d3c33hcgiwev3.cloudfront.net/bHMKq_OASzWzCqvzgIs1sA.processed/full/540p/index.webm?Expires=1678579200&amp;Signature=O0nl3FtMdDQQMLVOmkrTR7cvELFVT030ahVRA2zDPKsm1Sc2FEWWBHlRbGehpR9a8mVvjS5d1L0Z4neYTkrbAI~Rktuhev~lltCJ-E7Wfv7~lAqEjRYwjjlDGSx9SCcNNokF4PhVKdAgBq9oZTSsS9AZcbKUEvcEt-lwzPgWtl4_&amp;Key-Pair-Id=APKAJLTNE6QMUY6HBC5A" allow="fullscreen" allowfullscreen="" style="height:100%;width:100%; aspect-ratio: 16 / 9; "></iframe>


#points 
Linear regression is a machine learning model that tries to fit a straight line to the training data so that it can make accurate predictions on new data. To implement linear regression, we first define a cost function, which tells us how well the model is performing so that we can try to improve it. The model we use is a linear function of the form f(w, b) = wx + b, where w and b are the parameters or coefficients of the model that we can adjust during training. The value of w determines the slope of the line and b determines the y-intercept.

We want to find values for w and b that fit the data well, meaning the line defined by f is roughly passing through the training examples. To measure how well the line fits the training data, we construct a cost function that measures the squared difference between the predicted and actual target values for each training example. We then sum these squared errors and divide by 2m, where m is the number of training examples, to get the mean squared error. The cost function gives us a measure of how well the model is doing and we can use optimization algorithms to find the values of w and b that minimize the cost function.

###Question
![[Pasted image 20230311114009.png]]
![[Pasted image 20230311114115.png]]

